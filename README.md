# ğŸ› ï¸ Observa: Lightweight Log Aggregation + AI Insights

**Observa** is a minimalist, log aggregation system inspired by tools like Splunk. It supports log ingestion via API, in-memory storage, filtering, retry logic, and now integrates powerful AI-driven insights and alerting features using open-source LLMs.

---

## ğŸš€ Features

### ğŸ”„ Core Log System
- `POST /logs` â€” Send logs to system
- `GET /logs` â€” Retrieve logs (with filters: `service`, `level`)
- Built-in **Blocking Queue** with retry queue
- **In-memory log storage** with modular storage interface
- Unique `requestId` tracking in every API call

### ğŸ§  AI-Powered Capabilities
- `POST /logs/summary` â€” Summarize logs using local LLM (Mistral)
- `POST /logs/root-cause` â€” Estimate root cause from recent failures
- `POST /logs/chat` â€” Chat with your logs ("What happened in auth-service yesterday?")

### ğŸš¨ Alerting & Metrics
- `POST /alerts/rules` â€” Add alert rule in natural language
- `GET /alerts/triggered` â€” View triggered alerts
- `GET /logs/metrics` â€” View per-service log stats
- `GET /logs/daily-digest` â€” Daily AI summary of logs

---

## ğŸ“‚ Project Structure

```
com/
â””â”€â”€ observa/
    â”œâ”€â”€ controller/        # REST endpoints
    â”œâ”€â”€ service/           # Business logic
    â”œâ”€â”€ storage/           # In-memory log store
    â”œâ”€â”€ queue/             # LogQueue and RetryQueue
    â”œâ”€â”€ model/             # LogMessage, AlertRule etc.
    â”œâ”€â”€ dto/               # Request and response DTOs
    â”œâ”€â”€ filter/            # RequestIdFilter
    â”œâ”€â”€ util/              # PromptLoader and utilities
    â”œâ”€â”€ prompts/           # AI prompt templates
    â””â”€â”€ ObservaApplication.java
```

---

## ğŸ“¬ API Reference

| Endpoint | Method | Sample Request | Sample Response |
|----------|--------|----------------|-----------------|
| `/logs` | POST | `{ "service": "auth-service", "level": "ERROR", "message": "JWT expired" }` | `"Log received."` |
| `/logs` | GET | `/logs?service=auth-service&level=ERROR` | `[ { ... LogMessage } ]` |
| `/logs/summary` | POST | `{ "service": "payment-service" }` | `"Summary of log activity in payment-service..."` |
| `/logs/root-cause` | POST | `{ "service": "inventory-service" }` | `"Likely root cause: database latency..."` |
| `/logs/chat` | POST | `{ "query": "What happened in auth-service yesterday?" }` | `"There were 3 login failures and a token mismatch..."` |
| `/alerts/rules` | POST | `{ "service": "payment-service", "level": "ERROR", "threshold": 3, "windowMinutes": 10 }` | `"Alert rule added"` |
| `/alerts/triggered` | GET |  â€” | `[ { "service": "payment-service", "level": "ERROR", "message": "Triggered: 4 logs in 10 min" } ]` |
| `/logs/metrics` | GET | â€” | `{ "auth-service": { "INFO": 10, "ERROR": 5 }, ... }` |
| `/logs/daily-digest` | GET | â€” | `"Yesterday's summary: 5 auth failures, 2 payment errors..."` |

---

## ğŸ” Retry Queue

If the log queue is full, logs are pushed to a retry queue. Background worker retries every 2s.

---

## ğŸ§  Local LLM Setup (Mistral)

You can run this app with [Ollama](https://ollama.com) and the `mistral` model:

```bash
ollama run mistral
```

App will call Ollama's API on `http://localhost:11434`.

---

## ğŸŒ… Future Scope

- Save logs in persistent DB (Postgres, Mongo)
- Web UI for visualization
- Alerts via Email / Slack
- Schedule-based insights & metrics
- Fine-tuned log classification models

---

## ğŸ‘©â€ğŸ’» Built by @Sufia as a system design + AI exploration âœ¨
