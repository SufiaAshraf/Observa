# ğŸ¤– AI Integration Design - Observa (Updated)

This document outlines the updated architecture and flow for integrating AI capabilities into the Observa log aggregation system. It extends Observaâ€™s core functionality with log enrichment, summarization, and natural language querying using a locally hosted LLM (Mistral via Ollama).

---

## ğŸ¯ Goals

- Enrich individual logs with summary, classification, and anomaly detection
- Provide natural language summaries over time ranges or services
- Answer user questions about logs using LLM
- Keep all AI logic cleanly separated and modular

---

## ğŸ§± Final Project Structure (AI-ready)

```
observa/
â”œâ”€â”€ controller/
â”‚   â”œâ”€â”€ LogController.java
â”‚   â””â”€â”€ AIController.java                 # AI endpoints handler
â”‚
â”œâ”€â”€ dto/
â”‚   â”œâ”€â”€ LogRequest.java
â”‚   â”œâ”€â”€ LogResponse.java
â”‚   â”œâ”€â”€ AIAnalysisRequest.java           # Input for single log analysis
â”‚   â”œâ”€â”€ AIAnalysisResponse.java          # Output for single log analysis
â”‚   â”œâ”€â”€ AISummaryResponse.java           # Output for multi-log summary
â”‚   â”œâ”€â”€ AIQueryRequest.java              # Input for natural language log queries
â”‚   â””â”€â”€ AIQueryResponse.java             # Answer to natural language queries
â”‚
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ LogConsumer.java
â”‚   â”œâ”€â”€ RetryWorker.java
â”‚   â”œâ”€â”€ LogEnqueueService.java
â”‚   â”œâ”€â”€ LogAIService.java                # Core AI logic (calls Mistral)
â”‚   â””â”€â”€ LogSummaryService.java          # Filtering logs for summary/query
```

---

## ğŸŒ Endpoints

### 1. `POST /logs/ai-analyze`
Enrich a single log using AI.

**Input:**
```json
{
  "service": "auth-service",
  "level": "ERROR",
  "message": "JWT expired for user 983."
}
```

**Output:**
```json
{
  "classification": "token_expiry_error",
  "summary": "JWT token expired for user authentication request.",
  "anomalous": false
}
```

---

### 2. `GET /logs/summary?service=xyz&minutes=15`

Generate a summary from recent logs of a given service.

**Output:**
```json
{
  "summary": "Most logs in auth-service relate to failed login attempts and JWT expiration issues in the last 15 minutes."
}
```

---

### 3. `POST /logs/query-ai`

Accepts natural language queries about logs.

**Input:**
```json
{
  "question": "What was the most common error in payment-service today?"
}
```

**Output:**
```json
{
  "answer": "The most frequent error in payment-service was 'Timeout connecting to Stripe'. It occurred 23 times today."
}
```

---

## ğŸ§  How It Works

1. `AIController` receives request
2. `LogSummaryService` fetches logs if needed (for summary/query)
3. `LogAIService` constructs prompt + sends to Mistral via Ollama (`localhost:11434`)
4. Response is parsed and returned to client

---

## ğŸ“¦ Model Details

- Model: `mistralai/Mistral-7B-Instruct-v0.1`
- Runtime: [Ollama](https://ollama.com/) (local)
- API: `POST http://localhost:11434/api/generate`

---

## ğŸ”® Future Ideas

- Auto-enrich logs during ingestion (via `/logs`)
- Alert generation from AI analysis
- Visual dashboard for summaries and alerts
- Caching AI responses
- Offline summarization batches

